{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a5a442",
      "metadata": {
        "id": "80a5a442"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import struct\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b828482d",
      "metadata": {
        "id": "b828482d"
      },
      "outputs": [],
      "source": [
        "def read_binary(file_path):\n",
        "\n",
        "    # Инициализация списков для основных полей\n",
        "    power = []\n",
        "    age = []\n",
        "    coordinate_x = []\n",
        "    coordinate_y = []\n",
        "    angle_tetta = []\n",
        "    angle_phi = []\n",
        "    energy = []\n",
        "    time = []\n",
        "\n",
        "    # Дополнительные важные параметры\n",
        "    primary_particle = []  # PART0 (14 - p, 5626 - Fe)\n",
        "    primary_energy = []    # E0 в ГэВ\n",
        "    n_muons = []          # NMU (число мюонов в ШАЛ)\n",
        "    n_hadrons = []        # NHADR (число адронов в ШАЛ)\n",
        "    first_interaction_height = []  # H1INT (высота 1 взаимодействия в см)\n",
        "\n",
        "    with open(file_path, 'rb') as binary_file:\n",
        "        while True:\n",
        "            try:\n",
        "                # Пропускаем первые 3 поля (N_event, NRUN, NEVENT)\n",
        "                binary_file.read(4 * 3)\n",
        "\n",
        "                # Читаем тип первичной частицы (14 - p, 5626 - Fe)\n",
        "                part0 = struct.unpack('f', binary_file.read(4))[0]\n",
        "                primary_particle.append(part0)\n",
        "\n",
        "                # Читаем энергию первичной частицы (ГэВ)\n",
        "                e0 = struct.unpack('f', binary_file.read(4))[0]\n",
        "                primary_energy.append(e0)\n",
        "\n",
        "                # Чтение зенитного угла\n",
        "                tetta = struct.unpack('f', binary_file.read(4))[0]\n",
        "                angle_tetta.append(tetta)\n",
        "\n",
        "                # Чтение азимутального угла\n",
        "                phi = struct.unpack('f', binary_file.read(4))[0]\n",
        "                angle_phi.append(phi)\n",
        "\n",
        "                # Чтение координат оси ШАЛ\n",
        "                x0 = struct.unpack('f', binary_file.read(4))[0]\n",
        "                coordinate_x.append(x0)\n",
        "\n",
        "                y0 = struct.unpack('f', binary_file.read(4))[0]\n",
        "                coordinate_y.append(y0)\n",
        "\n",
        "                # Чтение высоты первого взаимодействия\n",
        "                h1int = struct.unpack('f', binary_file.read(4))[0]\n",
        "                first_interaction_height.append(h1int)\n",
        "\n",
        "                # Пропускаем NGAM, NEL\n",
        "                binary_file.read(4 * 2)\n",
        "\n",
        "                # Чтение числа адронов\n",
        "                nhadr = struct.unpack('f', binary_file.read(4))[0]\n",
        "                n_hadrons.append(nhadr)\n",
        "\n",
        "                # Чтение числа мюонов\n",
        "                nmu = struct.unpack('f', binary_file.read(4))[0]\n",
        "                n_muons.append(nmu)\n",
        "\n",
        "                # Чтение параметров ШАЛ\n",
        "                power_eas = struct.unpack('f', binary_file.read(4))[0]\n",
        "                power.append(math.log10(power_eas))\n",
        "\n",
        "                age_eas = struct.unpack('f', binary_file.read(4))[0]\n",
        "                age.append(age_eas)\n",
        "\n",
        "                # Пропускаем NVD_edep, NVD_npe, MuBundle, MuTrackLenNVD, nMuNVD, eMuNVD, eMuNVD1\n",
        "                binary_file.read(4 * 7)\n",
        "\n",
        "                # Пропускаем новые поля 2021 (23-34) и AmplKSM[7][4][4][6] (672 значения)\n",
        "                binary_file.read(4 * (12 + 672))\n",
        "\n",
        "                # Пропускаем новые поля 2021 (707-771)\n",
        "                binary_file.read(4 * 64)\n",
        "\n",
        "                # Пропускаем EdepCntSCT[9][5][2] (90 значений)\n",
        "                binary_file.read(4 * 90)\n",
        "\n",
        "                # Чтение EdepDetNE[9][4][4] (144 значения) - используем для energy\n",
        "                edep_det_ne = struct.unpack('f'*144, binary_file.read(4*144))\n",
        "                energy.append(edep_det_ne)\n",
        "\n",
        "                # Чтение TimDetNE[9][4][4][4] (576 значений) - берем пороговые времена\n",
        "                tim_det_ne = struct.unpack('f'*576, binary_file.read(4*576))\n",
        "                threshold_time = tim_det_ne[::4]  # Берем каждое 4-е значение (max время)\n",
        "                time.append(threshold_time)\n",
        "\n",
        "                # Пропускаем EdepStNE[9][4] (36 значений) и TimStNE[9][4][4] (144 значения)\n",
        "                binary_file.read(4 * (36 + 144))\n",
        "\n",
        "                # Чтение маркера (1762)\n",
        "                binary_file.read(4)\n",
        "            except struct.error:\n",
        "                # Достигнут конец файла\n",
        "                break\n",
        "\n",
        "    # Создание DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'power': power,\n",
        "        'age': age,\n",
        "        'x': coordinate_x,\n",
        "        'y': coordinate_y,\n",
        "        'tetta': angle_tetta,\n",
        "        'phi': angle_phi,\n",
        "        'energy': energy,\n",
        "        'threshold_time': time,\n",
        "        'primary_particle': primary_particle,\n",
        "        'primary_energy': primary_energy,\n",
        "        'n_muons': n_muons,\n",
        "        'n_hadrons': n_hadrons,\n",
        "        'first_interaction_height': first_interaction_height\n",
        "    })\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare_data(data):\n",
        "    static_features = data[['primary_particle', 'primary_energy', 'n_muons',\n",
        "                           'n_hadrons', 'first_interaction_height']]\n",
        "    sequence_energy = data[[f'energy_{i}' for i in range(144)]]\n",
        "    sequence_time = data[[f'threshold_time_{i}' for i in range(144)]]\n",
        "\n",
        "    # Извлечение целей\n",
        "    targets = data[['power', 'age', 'x', 'y', 'tetta', 'phi']]\n",
        "\n",
        "    # Преобразование phi в sin(phi) и cos(phi)\n",
        "    # phi_rad = targets['phi']\n",
        "    targets['sin_phi'] = np.sin(targets['phi'])\n",
        "    targets['cos_phi'] = np.cos(targets['phi'])\n",
        "    targets = targets.drop('phi', axis=1)\n",
        "\n",
        "    # Разделение данных\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        pd.concat([static_features, sequence_energy, sequence_time], axis=1),\n",
        "        targets,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Препроцессинг: one-hot для primary_particle, нормализация для остальных\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(), ['primary_particle']),\n",
        "            ('num', StandardScaler(), ['primary_energy', 'n_muons',\n",
        "                                      'n_hadrons', 'first_interaction_height'])\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    # Применение препроцессинга к статическим признакам\n",
        "    static_cols = ['primary_particle', 'primary_energy', 'n_muons',\n",
        "                  'n_hadrons', 'first_interaction_height']\n",
        "    X_train_static = preprocessor.fit_transform(X_train[static_cols])\n",
        "    X_test_static = preprocessor.transform(X_test[static_cols])\n",
        "\n",
        "    # Получение имен признаков после one-hot кодирования\n",
        "    cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(['primary_particle'])\n",
        "    num_features = ['primary_energy', 'n_muons', 'n_hadrons', 'first_interaction_height']\n",
        "    all_static_features = list(cat_features) + num_features\n",
        "\n",
        "    # Подготовка последовательностей\n",
        "    energy_cols = [f'energy_{i}' for i in range(144)]\n",
        "    time_cols = [f'threshold_time_{i}' for i in range(144)]\n",
        "\n",
        "    X_train_energy = X_train[energy_cols].values\n",
        "    X_train_time = X_train[time_cols].values\n",
        "    X_test_energy = X_test[energy_cols].values\n",
        "    X_test_time = X_test[time_cols].values\n",
        "\n",
        "    # Создание 3D тензоров (samples, timesteps, features)\n",
        "    X_train_seq = np.stack([X_train_energy, X_train_time], axis=2)\n",
        "    X_test_seq = np.stack([X_test_energy, X_test_time], axis=2)\n",
        "\n",
        "    # Нормализация последовательностей\n",
        "    seq_scaler = StandardScaler()\n",
        "    X_train_seq = seq_scaler.fit_transform(\n",
        "        X_train_seq.reshape(-1, X_train_seq.shape[2])\n",
        "    ).reshape(X_train_seq.shape)\n",
        "\n",
        "    X_test_seq = seq_scaler.transform(\n",
        "        X_test_seq.reshape(-1, X_test_seq.shape[2])\n",
        "    ).reshape(X_test_seq.shape)\n",
        "\n",
        "    return (\n",
        "        X_train_static, X_train_seq, y_train.values,\n",
        "        X_test_static, X_test_seq, y_test.values,\n",
        "        preprocessor, seq_scaler, all_static_features\n",
        "    )"
      ],
      "metadata": {
        "id": "LqTXsdSF_ck7"
      },
      "id": "LqTXsdSF_ck7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dyLHc1lgWUmw",
      "metadata": {
        "id": "dyLHc1lgWUmw"
      },
      "outputs": [],
      "source": [
        "os.makedirs('plots', exist_ok=True)\n",
        "\n",
        "data = read_binary('/content/spe27p_100k_2022_correct.dat')\n",
        "\n",
        "energy_df = pd.DataFrame(data['energy'].to_list(), columns=[f\"energy_{i}\" for i in range(144)])\n",
        "data = pd.concat([data, energy_df], axis=1)\n",
        "threshold_times_df = pd.DataFrame(data['threshold_time'].to_list(), columns=[f\"threshold_time_{i}\" for i in range(144)])\n",
        "data = pd.concat([data, threshold_times_df], axis=1)\n",
        "data = data.drop(columns = ['energy', 'threshold_time'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16bac3f7",
      "metadata": {
        "id": "16bac3f7"
      },
      "source": [
        "# Torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8003aa",
      "metadata": {
        "id": "4d8003aa"
      },
      "outputs": [],
      "source": [
        "class HybridDataset(Dataset):\n",
        "    def __init__(self, static_features, sequence_features, targets):\n",
        "        self.static_features = torch.tensor(static_features, dtype=torch.float32)\n",
        "        self.sequence_features = torch.tensor(sequence_features, dtype=torch.float32)\n",
        "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.static_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.static_features[idx], self.sequence_features[idx]), self.targets[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc50960",
      "metadata": {
        "id": "2bc50960"
      },
      "outputs": [],
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, static_input_size, seq_input_size, hidden_size, num_layers, num_targets):\n",
        "        super().__init__()\n",
        "\n",
        "        # LSTM для временных рядов\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=seq_input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # Полносвязная сеть для статических признаков\n",
        "        self.static_fc = nn.Sequential(\n",
        "            nn.Linear(static_input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # Объединенные слои\n",
        "        self.combined_fc = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2 + 128, 256),  # 2* для bidirectional\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "        # Выходные головы для 7 целей (power, age, x, y, tetta, sin_phi, cos_phi)\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(128, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 1)\n",
        "            ) for _ in range(num_targets)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        static_input, seq_input = x\n",
        "\n",
        "        # Обработка временных рядов\n",
        "        lstm_out, _ = self.lstm(seq_input)\n",
        "        seq_features = lstm_out[:, -1, :]  # Берем последний временной шаг\n",
        "\n",
        "        # Обработка статических признаков\n",
        "        static_features = self.static_fc(static_input)\n",
        "\n",
        "        # Объединение признаков\n",
        "        combined = torch.cat([static_features, seq_features], dim=1)\n",
        "        features = self.combined_fc(combined)\n",
        "\n",
        "        # Выходные головы\n",
        "        outputs = [head(features) for head in self.heads]\n",
        "\n",
        "        return torch.cat(outputs, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80624713",
      "metadata": {
        "id": "80624713"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs=100):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Функция потерь - MSE для всех целей\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, 'min', patience=10, factor=0.5, verbose=True\n",
        "    )\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        for (static, seq), targets in tqdm(train_loader):\n",
        "            static, seq, targets = static.to(device), seq.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model((static, seq))\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for (static, seq), targets in val_loader:\n",
        "                static, seq, targets = static.to(device), seq.to(device), targets.to(device)\n",
        "                outputs = model((static, seq))\n",
        "                loss = criterion(outputs, targets)\n",
        "                epoch_val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Сохраняем лучшую модель\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"Saved new best model with val loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} | '\n",
        "              f'Train Loss: {avg_train_loss:.4f} | '\n",
        "              f'Val Loss: {avg_val_loss:.4f} | '\n",
        "              f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "    # Загрузка лучшей модели\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "    # График обучения\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.savefig('plots/training_curve.png')\n",
        "    plt.close()\n",
        "\n",
        "    return model\n",
        "\n",
        "# 5. Функция для восстановления phi из sin и cos\n",
        "def recover_phi(sin_phi, cos_phi):\n",
        "    phi_rad = np.arctan2(sin_phi, cos_phi)\n",
        "    phi_deg = np.degrees(phi_rad)\n",
        "    # Нормализация к диапазону [0, 360)\n",
        "    phi_deg = np.where(phi_deg < 0, phi_deg + 360, phi_deg)\n",
        "    return phi_deg\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (static, seq), targets in tqdm(test_loader):\n",
        "            static, seq = static.to(device), seq.to(device)\n",
        "            outputs = model((static, seq)).cpu().numpy()\n",
        "\n",
        "            all_predictions.append(outputs)\n",
        "            all_targets.append(targets.numpy())\n",
        "\n",
        "    # Объединяем результаты\n",
        "    predictions = np.vstack(all_predictions)\n",
        "    targets = np.vstack(all_targets)\n",
        "\n",
        "    # Разделяем предсказания на отдельные цели\n",
        "    pred_power = predictions[:, 0]\n",
        "    pred_age = predictions[:, 1]\n",
        "    pred_x = predictions[:, 2]\n",
        "    pred_y = predictions[:, 3]\n",
        "    pred_tetta = predictions[:, 4]\n",
        "    pred_sin_phi = predictions[:, 5]\n",
        "    pred_cos_phi = predictions[:, 6]\n",
        "\n",
        "    # Восстанавливаем phi\n",
        "    pred_phi = recover_phi(pred_sin_phi, pred_cos_phi)\n",
        "\n",
        "    # Аналогично для истинных значений\n",
        "    true_power = targets[:, 0]\n",
        "    true_age = targets[:, 1]\n",
        "    true_x = targets[:, 2]\n",
        "    true_y = targets[:, 3]\n",
        "    true_tetta = targets[:, 4]\n",
        "    true_phi = np.degrees(np.arctan2(targets[:, 5], targets[:, 6]))\n",
        "    true_phi = np.where(true_phi < 0, true_phi + 360, true_phi)\n",
        "\n",
        "    # Рассчитываем метрики для каждой цели\n",
        "    metrics = {}\n",
        "    target_names = ['power', 'age', 'x', 'y', 'tetta', 'phi']\n",
        "\n",
        "    for i, name in enumerate(target_names[:5]):  # Для power, age, x, y, tetta\n",
        "        true_vals = targets[:, i]\n",
        "        pred_vals = predictions[:, i]\n",
        "\n",
        "        mse = np.mean((true_vals - pred_vals) ** 2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = np.mean(np.abs(true_vals - pred_vals))\n",
        "        r2 = 1 - np.sum((true_vals - pred_vals) ** 2) / np.sum((true_vals - np.mean(true_vals)) ** 2)\n",
        "\n",
        "        metrics[name] = {\n",
        "            'MSE': mse,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2\n",
        "        }\n",
        "\n",
        "        # Визуализация предсказаний\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.scatter(true_vals, pred_vals, alpha=0.5)\n",
        "        plt.plot([min(true_vals), max(true_vals)],\n",
        "                 [min(true_vals), max(true_vals)], 'r--')\n",
        "        plt.xlabel('True Values')\n",
        "        plt.ylabel('Predictions')\n",
        "        plt.title(f'Regression Plot for {name}')\n",
        "        plt.savefig(f'plots/regression_{name}.png')\n",
        "        plt.close()\n",
        "\n",
        "    # Специальная обработка для phi\n",
        "    phi_diff = np.abs(true_phi - pred_phi)\n",
        "    # Учитываем циклическую природу угла\n",
        "    phi_diff = np.minimum(phi_diff, 360 - phi_diff)\n",
        "\n",
        "    metrics['phi'] = {\n",
        "        'MAE': np.mean(phi_diff),\n",
        "        'RMSE': np.sqrt(np.mean(phi_diff ** 2)),\n",
        "        'Accuracy_5deg': np.mean(phi_diff <= 5) * 100,\n",
        "        'Accuracy_10deg': np.mean(phi_diff <= 10) * 100\n",
        "    }\n",
        "\n",
        "    # Визуализация для phi\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(true_phi, pred_phi, alpha=0.5)\n",
        "    plt.plot([0, 360], [0, 360], 'r--')\n",
        "    plt.xlabel('True Phi (degrees)')\n",
        "    plt.ylabel('Predicted Phi (degrees)')\n",
        "    plt.title('Regression Plot for Phi')\n",
        "    plt.savefig('plots/regression_phi.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Распределение ошибок phi\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(phi_diff, bins=50, alpha=0.7)\n",
        "    plt.xlabel('Absolute Error (degrees)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Error Distribution for Phi')\n",
        "    plt.savefig('plots/error_distribution_phi.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Круговой график для phi\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(111, projection='polar')\n",
        "    ax.scatter(np.radians(true_phi), np.ones_like(true_phi),\n",
        "               alpha=0.5, label='True', s=10)\n",
        "    ax.scatter(np.radians(pred_phi), np.ones_like(pred_phi) * 1.1,\n",
        "               alpha=0.5, label='Predicted', s=10)\n",
        "    ax.set_theta_zero_location('N')\n",
        "    ax.set_theta_direction(-1)\n",
        "    ax.set_rticks([])\n",
        "    plt.legend()\n",
        "    plt.title('Phi Predictions Comparison')\n",
        "    plt.savefig('plots/polar_phi_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    return metrics, predictions, targets\n",
        "\n",
        "# 7. Функция для предсказания на новых данных\n",
        "def predict_new_data(model, preprocessor, seq_scaler, new_data_path):\n",
        "    # Загрузка новых данных\n",
        "    new_data = pd.read_csv(new_data_path)\n",
        "\n",
        "    # Извлечение признаков\n",
        "    static_features = new_data[['primary_particle', 'primary_energy', 'n_muons',\n",
        "                               'n_hadrons', 'first_interaction_height']]\n",
        "    energy_cols = [f'energy_{i}' for i in range(144)]\n",
        "    time_cols = [f'threshold_time_{i}' for i in range(144)]\n",
        "\n",
        "    # Препроцессинг\n",
        "    new_static = preprocessor.transform(static_features)\n",
        "\n",
        "    # Подготовка последовательностей\n",
        "    new_energy = new_data[energy_cols].values\n",
        "    new_time = new_data[time_cols].values\n",
        "    new_seq = np.stack([new_energy, new_time], axis=2)\n",
        "    new_seq = seq_scaler.transform(\n",
        "        new_seq.reshape(-1, new_seq.shape[2])\n",
        "    ).reshape(new_seq.shape)\n",
        "\n",
        "    # Создание DataLoader\n",
        "    dataset = HybridDataset(\n",
        "        new_static,\n",
        "        new_seq,\n",
        "        np.zeros((len(new_data), 7))  # Фиктивные цели\n",
        "    )\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Предсказание\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (static, seq), _ in loader:\n",
        "            static, seq = static.to(device), seq.to(device)\n",
        "            outputs = model((static, seq)).cpu().numpy()\n",
        "            all_predictions.append(outputs)\n",
        "\n",
        "    predictions = np.vstack(all_predictions)\n",
        "\n",
        "    # Восстановление phi\n",
        "    pred_sin_phi = predictions[:, 5]\n",
        "    pred_cos_phi = predictions[:, 6]\n",
        "    pred_phi = recover_phi(pred_sin_phi, pred_cos_phi)\n",
        "\n",
        "    # Создание DataFrame с результатами\n",
        "    result_df = pd.DataFrame({\n",
        "        'power': predictions[:, 0],\n",
        "        'age': predictions[:, 1],\n",
        "        'x': predictions[:, 2],\n",
        "        'y': predictions[:, 3],\n",
        "        'tetta': predictions[:, 4],\n",
        "        'phi': pred_phi\n",
        "    })\n",
        "\n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8990bc15",
      "metadata": {
        "id": "8990bc15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee0a810-1b57-4840-f8d2-ea71c310b00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-31-3399696855.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  targets['sin_phi'] = np.sin(targets['phi'])\n",
            "/tmp/ipython-input-31-3399696855.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  targets['cos_phi'] = np.cos(targets['phi'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Static features: 5\n",
            "Sequence shape: (80000, 144, 2)\n",
            "Targets shape: (80000, 7)\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 20\n",
        "HIDDEN_SIZE = 256\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "# 1. Загрузка данных\n",
        "print(\"Loading and preprocessing data...\")\n",
        "(X_train_static, X_train_seq, y_train,\n",
        "  X_test_static, X_test_seq, y_test,\n",
        "  preprocessor, seq_scaler, static_feature_names) = load_and_prepare_data(data)\n",
        "\n",
        "print(f\"Static features: {len(static_feature_names)}\")\n",
        "print(f\"Sequence shape: {X_train_seq.shape}\")\n",
        "print(f\"Targets shape: {y_train.shape}\")\n",
        "\n",
        "# 2. Создание Dataset и DataLoader\n",
        "train_dataset = HybridDataset(X_train_static, X_train_seq, y_train)\n",
        "test_dataset = HybridDataset(X_test_static, X_test_seq, y_test)\n",
        "\n",
        "# Разделение на тренировочную и валидационную выборки\n",
        "train_size = int(0.85 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f7133b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18f7133b",
        "outputId": "ebfeea24-828a-4608-ed36-f91ca6ecf7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model architecture:\n",
            "HybridModel(\n",
            "  (lstm): LSTM(2, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (static_fc): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            "  (combined_fc): Sequential(\n",
            "    (0): Linear(in_features=640, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.4, inplace=False)\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0-6): 7 x Sequential(\n",
            "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total parameters: 2,366,471\n",
            "Trainable parameters: 2,366,471\n"
          ]
        }
      ],
      "source": [
        "static_input_size = X_train_static.shape[1]\n",
        "seq_input_size = X_train_seq.shape[2]  # 2 признака (energy и time)\n",
        "num_targets = 7  # 6 исходных целей, но phi заменен на sin и cos\n",
        "model = HybridModel(\n",
        "    static_input_size=static_input_size,\n",
        "    seq_input_size=seq_input_size,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_targets=num_targets\n",
        ")\n",
        "\n",
        "print(f\"\\nModel architecture:\\n{model}\")\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train_model(model, train_loader, val_loader, NUM_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5KdE3xtGTLc",
        "outputId": "1c4a737f-d4dc-4004-8a28-c7f5e855cec2"
      },
      "id": "I5KdE3xtGTLc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1063/1063 [00:58<00:00, 18.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 77.9959\n",
            "Epoch 1/20 | Train Loss: 181.5760 | Val Loss: 77.9959 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 58.7914\n",
            "Epoch 2/20 | Train Loss: 72.5683 | Val Loss: 58.7914 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 52.4363\n",
            "Epoch 3/20 | Train Loss: 60.1503 | Val Loss: 52.4363 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 44.6386\n",
            "Epoch 4/20 | Train Loss: 53.1245 | Val Loss: 44.6386 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 43.4555\n",
            "Epoch 5/20 | Train Loss: 48.9846 | Val Loss: 43.4555 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 41.5053\n",
            "Epoch 6/20 | Train Loss: 46.3039 | Val Loss: 41.5053 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 | Train Loss: 45.1456 | Val Loss: 49.3424 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 | Train Loss: 43.4058 | Val Loss: 58.3740 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 35.1337\n",
            "Epoch 9/20 | Train Loss: 41.1053 | Val Loss: 35.1337 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 | Train Loss: 38.8661 | Val Loss: 35.9014 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 32.5909\n",
            "Epoch 11/20 | Train Loss: 37.5314 | Val Loss: 32.5909 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 31.5877\n",
            "Epoch 12/20 | Train Loss: 36.7512 | Val Loss: 31.5877 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 30.5911\n",
            "Epoch 13/20 | Train Loss: 36.0449 | Val Loss: 30.5911 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 30.2426\n",
            "Epoch 14/20 | Train Loss: 35.6650 | Val Loss: 30.2426 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 30.2160\n",
            "Epoch 15/20 | Train Loss: 34.9019 | Val Loss: 30.2160 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 30.0665\n",
            "Epoch 16/20 | Train Loss: 34.8921 | Val Loss: 30.0665 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 29.1104\n",
            "Epoch 17/20 | Train Loss: 34.1109 | Val Loss: 29.1104 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 | Train Loss: 33.9029 | Val Loss: 30.3576 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:57<00:00, 18.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 | Train Loss: 33.5244 | Val Loss: 31.0390 | LR: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1063/1063 [00:56<00:00, 18.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved new best model with val loss: 28.5702\n",
            "Epoch 20/20 | Train Loss: 33.2199 | Val Loss: 28.5702 | LR: 0.001000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbfd3e02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbfd3e02",
        "outputId": "7291d826-bf16-4bf5-c51a-42970bc54de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:08<00:00, 38.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance Metrics:\n",
            "\n",
            "power:\n",
            "MSE: 0.1967\n",
            "RMSE: 0.4435\n",
            "MAE: 0.2727\n",
            "R2: 0.4830\n",
            "\n",
            "age:\n",
            "MSE: 0.0041\n",
            "RMSE: 0.0640\n",
            "MAE: 0.0496\n",
            "R2: 0.0382\n",
            "\n",
            "x:\n",
            "MSE: 83.1434\n",
            "RMSE: 9.1183\n",
            "MAE: 6.4189\n",
            "R2: 0.8433\n",
            "\n",
            "y:\n",
            "MSE: 126.6561\n",
            "RMSE: 11.2542\n",
            "MAE: 7.4314\n",
            "R2: 0.9173\n",
            "\n",
            "tetta:\n",
            "MSE: 20.6932\n",
            "RMSE: 4.5490\n",
            "MAE: 3.2865\n",
            "R2: 0.8536\n",
            "\n",
            "phi:\n",
            "MAE: 89.6362\n",
            "RMSE: 103.4708\n",
            "Accuracy_5deg: 2.8200\n",
            "Accuracy_10deg: 5.5550\n"
          ]
        }
      ],
      "source": [
        "# 5. Оценка\n",
        "print(\"\\nEvaluating model...\")\n",
        "metrics, predictions, targets = evaluate_model(trained_model, test_loader)\n",
        "\n",
        "# Вывод метрик\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "for target, values in metrics.items():\n",
        "    print(f\"\\n{target}:\")\n",
        "    for metric, value in values.items():\n",
        "        print(f\"{metric}: {value:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}